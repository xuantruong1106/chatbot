from sentence_transformers import SentenceTransformer
import streamlit as st
import pandas as pd
import torch
from connectsql import (
    connect_to_postgresql, is_question_duplicate, load_faq, add_faq,
    load_unanswered_logs, load_unanswered_questions, show_statistics, update_faq, delete_faq
)
from pathlib import Path
from transformers import pipeline
from sentence_transformers import util
from PyPDF2 import PdfReader
from transformers import pipeline, GPT2LMHeadModel, GPT2Tokenizer
from transformers import T5ForConditionalGeneration, AutoTokenizer
import logging
from typing import List, Tuple, Optional
from tqdm import tqdm
import numpy as np
import re

# Thi·∫øt l·∫≠p logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

docs_path = Path("D:\\chatbot\\docs")


def is_question_duplicate(question):
    try:
        conn = connect_to_postgresql()
        cursor = conn.cursor()

        cursor.execute(
            "SELECT COUNT(*) FROM faq WHERE question = %s", (question,))
        count = cursor.fetchone()[0]

        cursor.close()
        conn.close()

        return count > 0
    except Exception as e:
        print(f"L·ªói khi ki·ªÉm tra c√¢u h·ªèi: {e}")
        return False


class QAGenerator:
    def __init__(self):
        self.device = torch.device(
            'cuda' if torch.cuda.is_available() else 'cpu')
        self.model = T5ForConditionalGeneration.from_pretrained(
            "VietAI/vit5-base").to(self.device)
        self.tokenizer = AutoTokenizer.from_pretrained("VietAI/vit5-base")
        self.similarity_model = SentenceTransformer(
            'VoVanPhuc/sup-SimCSE-VietNamese-phobert-base')

    def preprocess_text(self, text: str) -> str:
        # Chu·∫©n h√≥a text
        text = re.sub(r'\s+', ' ', text)
        text = text.strip()
        return text

    def postprocess_text(self, text: str) -> str:
        # X·ª≠ l√Ω output
        text = re.sub(
            r'[^\x00-\x7F\u0100-\u017F\u0180-\u024F\u1EA0-\u1EF9\u0300-\u036f]+', '', text)
        text = re.sub(r'\s+', ' ', text)
        return text.strip()

    def generate_question(self, context: str) -> list[str]:
        context = self.preprocess_text(context)
        input_text = f"h√£y ƒë·∫∑t c√¢u h·ªèi d·ª±a tr√™n ƒëo·∫°n vƒÉn sau: {context}"

        inputs = self.tokenizer(input_text,
                                return_tensors="pt",
                                max_length=512,
                                truncation=True).to(self.device)

        outputs = self.model.generate(
            inputs.input_ids,
            max_length=128,
            min_length=10,
            num_return_sequences=3,
            num_beams=5,
            temperature=0.7,
            top_k=50,
            top_p=0.95,
            no_repeat_ngram_size=2,
            do_sample=True
        )

        questions = []
        for output in outputs:
            question = self.tokenizer.decode(output, skip_special_tokens=True)
            question = self.postprocess_text(question)
            if len(question) > 10:
                questions.append(question)

        return questions

    def generate_answer(self, question: str, context: str) -> str:
        question = self.preprocess_text(question)
        context = self.preprocess_text(context)

        input_text = f"tr·∫£ l·ªùi c√¢u h·ªèi sau d·ª±a tr√™n ƒëo·∫°n vƒÉn: c√¢u h·ªèi: {question} ƒëo·∫°n vƒÉn: {context}"

        inputs = self.tokenizer(input_text,
                                return_tensors="pt",
                                max_length=512,
                                truncation=True).to(self.device)

        outputs = self.model.generate(
            inputs.input_ids,
            max_length=256,
            min_length=20,
            num_beams=5,
            temperature=0.7,
            top_k=50,
            top_p=0.95,
            no_repeat_ngram_size=2
        )

        answer = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
        return self.postprocess_text(answer)

    def evaluate_qa_quality(self, question: str, answer: str, context: str) -> bool:
        # Ki·ªÉm tra ƒë·ªô d√†i t·ªëi thi·ªÉu
        if len(question) < 10 or len(answer) < 20:
            return False

        # Ki·ªÉm tra ch·∫•t l∆∞·ª£ng vƒÉn b·∫£n
        if not re.match(r'^[\w\s\.,\?\!]+$', question) or not re.match(r'^[\w\s\.,\?\!]+$', answer):
            return False

        # ƒê√°nh gi√° ƒë·ªô t∆∞∆°ng ƒë·ªìng
        try:
            embeddings = self.similarity_model.encode(
                [question, answer, context])
            q_c_similarity = np.dot(embeddings[0], embeddings[2])
            a_c_similarity = np.dot(embeddings[1], embeddings[2])
            return q_c_similarity > 0.5 and a_c_similarity > 0.6
        except:
            return False


class PDFProcessor:
    @staticmethod
    def get_pdf_text(pdf_path: Path) -> str:
        try:
            reader = PdfReader(pdf_path)
            text = ""
            for page in reader.pages:
                text += page.extract_text()
            return text
        except Exception as e:
            logger.error(f"L·ªói ƒë·ªçc PDF: {e}")
            return ""

    @staticmethod
    def improve_chunk_quality(text: str, chunk_size: int = 512, overlap: int = 50) -> List[str]:
        try:
            sentences = text.split('.')
            chunks = []
            current_chunk = []
            current_length = 0

            for sentence in sentences:
                sentence = sentence.strip() + '.'
                sentence_length = len(sentence.split())

                if current_length + sentence_length > chunk_size:
                    if current_chunk:
                        chunks.append(' '.join(current_chunk))
                    current_chunk = [sentence]
                    current_length = sentence_length
                else:
                    current_chunk.append(sentence)
                    current_length += sentence_length

            if current_chunk:
                chunks.append(' '.join(current_chunk))

            return chunks
        except Exception as e:
            logger.error(f"L·ªói x·ª≠ l√Ω chunks: {e}")
            return []


def process_pdf_and_generate_qa(pdf_path: Path) -> List[Tuple[str, str]]:
    try:
        processor = PDFProcessor()
        generator = QAGenerator()

        # ƒê·ªçc v√† x·ª≠ l√Ω PDF
        pdf_text = processor.get_pdf_text(pdf_path)
        if not pdf_text:
            st.error("Kh√¥ng th·ªÉ ƒë·ªçc n·ªôi dung PDF")
            return []

        # Chia th√†nh chunks v√† sinh Q&A
        chunks = processor.improve_chunk_quality(pdf_text)
        qa_pairs = []

        with st.spinner("ƒêang sinh c√¢u h·ªèi v√† c√¢u tr·∫£ l·ªùi..."):
            progress_bar = st.progress(0)
            for i, chunk in enumerate(chunks):
                if len(chunk.strip()) < 50:
                    continue

                questions = generator.generate_question(chunk)
                for question in questions:
                    answer = generator.generate_answer(question, chunk)
                    if answer and generator.evaluate_qa_quality(question, answer, chunk):
                        qa_pairs.append((question, answer))

                progress_bar.progress((i + 1) / len(chunks))

        return qa_pairs

    except Exception as e:
        logger.error(f"L·ªói trong qu√° tr√¨nh x·ª≠ l√Ω: {e}")
        st.error(f"C√≥ l·ªói x·∫£y ra: {str(e)}")
        return []


def admin_interface():
    if not st.session_state.get('authenticated', False):
        st.warning("B·∫°n ch∆∞a ƒëƒÉng nh·∫≠p. Vui l√≤ng ƒëƒÉng nh·∫≠p tr∆∞·ªõc.")
        st.stop()

    # Sidebar
    with st.sidebar:
        st.header("üîê Th√¥ng tin t√†i kho·∫£n")
        st.write(f"**üë§ T√™n ng∆∞·ªùi d√πng:** {st.session_state['username']}")
        st.write(
            f"**üîì Vai tr√≤:** {'Admin' if st.session_state['username'] == 'admin' else 'Ng∆∞·ªùi d√πng'}")
        st.divider()
        if st.button("üö™ƒêƒÉng xu·∫•t"):
            st.session_state['authenticated'] = False
            st.rerun()

    st.title("‚ú® Qu·∫£n l√Ω D·ªØ li·ªáu Chatbot")

    # Tabs ch√≠nh
    tab_add, tab_edit, tab_load_logs, tab_statistics, tab_generate_question = st.tabs(
        ["‚ûï Th√™m D·ªØ li·ªáu", "‚úèÔ∏è Ch·ªânh s·ª≠a D·ªØ li·ªáu",
            "üìã Qu·∫£n l√Ω Log", "Th·ªëng k√™", "ü™Ñ D·ª± ƒëo√°n d·ªØ li·ªáu"]
    )

    with tab_add:
        st.header("‚ûï Th√™m D·ªØ li·ªáu")
        st.markdown("### Nh·∫≠p th√¥ng tin c√¢u h·ªèi v√† c√¢u tr·∫£ l·ªùi:")
        col1, col2 = st.columns(2)
        with col1:
            question = st.text_input("C√¢u h·ªèi:")
        with col2:
            answer = st.text_area("C√¢u tr·∫£ l·ªùi:")

        st.markdown("---")
        if st.button("Th√™m v√†o FAQ", key="add_data"):
            if question and answer:
                if add_faq(question, answer):
                    st.success("‚úÖ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c th√™m th√†nh c√¥ng!")
                else:
                    st.warning("‚ö†Ô∏è C√¢u h·ªèi n√†y ƒë√£ t·ªìn t·∫°i!")
            else:
                st.error("‚õî Vui l√≤ng nh·∫≠p ƒë·∫ßy ƒë·ªß th√¥ng tin!")

        with st.expander("üìÑ Upload File PDF"):
            uploaded_pdf = st.file_uploader("Ch·ªçn file PDF:", type="pdf")
            if uploaded_pdf:
                pdf_path = docs_path / uploaded_pdf.name
                with open(pdf_path, "wb") as f:
                    f.write(uploaded_pdf.getbuffer())
                st.success(f"üìÇ File **{uploaded_pdf.name}** ƒë√£ ƒë∆∞·ª£c l∆∞u!")

        st.markdown("---")
        st.subheader("üìÑ Upload File Excel")

        uploaded_excel = st.file_uploader(
            "Ch·ªçn file Excel ƒë·ªÉ upload:", type=["xlsx", "xls"])

        if uploaded_excel:
            try:
                df = pd.read_excel(uploaded_excel)
                if st.button("Th√™m d·ªØ li·ªáu t·ª´ Excel", key="add_from_excel"):
                    added_count = 0
                    skipped_count = 0
                    for _, row in df.iterrows():
                        question, answer = row['Question'], row['Answer']
                        if question and answer:
                            if is_question_duplicate(question):
                                skipped_count += 1  # ƒê·∫øm s·ªë c√¢u h·ªèi b·ªã b·ªè qua
                            else:
                                if add_faq(question, answer):
                                    added_count += 1  # ƒê·∫øm s·ªë c√¢u h·ªèi ƒë∆∞·ª£c th√™m
                    st.success(
                        f"‚úÖ ƒê√£ th√™m {added_count} c√¢u h·ªèi t·ª´ file Excel!")
                    if skipped_count > 0:
                        st.warning(
                            f"‚ö†Ô∏è B·ªè qua {skipped_count} c√¢u h·ªèi do ƒë√£ t·ªìn t·∫°i trong c∆° s·ªü d·ªØ li·ªáu.")
                else:
                    st.error("‚õî File Excel ph·∫£i c√≥ c·ªôt 'Question' v√† 'Answer'!")
            except Exception as e:
                st.error(f"‚õî L·ªói khi ƒë·ªçc file Excel: {e}")

    with tab_edit:
        st.header("‚úèÔ∏è Ch·ªânh s·ª≠a D·ªØ li·ªáu")  # Th√™m bi·ªÉu t∆∞·ª£ng cho ti√™u ƒë·ªÅ
        questions, faq_data = load_faq()  # Gi·∫£ s·ª≠ faq_data ch·ª©a c·∫£ c√¢u tr·∫£ l·ªùi

        # H·ªôp ch·ªçn c√¢u h·ªèi v·ªõi bi·ªÉu t∆∞·ª£ng
        selected_question = st.selectbox("üîç Ch·ªçn c√¢u h·ªèi:", questions)

        # T√¨m c√¢u tr·∫£ l·ªùi t∆∞∆°ng ·ª©ng v·ªõi c√¢u h·ªèi ƒë√£ ch·ªçn
        current_answer = faq_data[selected_question]

        # Nh·∫≠p c√¢u h·ªèi m·ªõi v√† c√¢u tr·∫£ l·ªùi m·ªõi
        new_question = st.text_input(
            "‚úèÔ∏è C·∫≠p nh·∫≠t c√¢u h·ªèi:", value=selected_question)
        # Hi·ªÉn th·ªã c√¢u tr·∫£ l·ªùi c≈©
        new_answer = st.text_area(
            "üìù C·∫≠p nh·∫≠t c√¢u tr·∫£ l·ªùi:", value=current_answer)

        col1, col2 = st.columns(2)

        # C·ªôt C·∫≠p nh·∫≠t v·ªõi bi·ªÉu t∆∞·ª£ng
        with col1:
            if st.button("‚úîÔ∏è C·∫≠p nh·∫≠t", key="update_data"):
                update_faq(selected_question, new_question, new_answer)
                st.success("‚úÖ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c c·∫≠p nh·∫≠t!")

        # C·ªôt X√≥a v·ªõi bi·ªÉu t∆∞·ª£ng
        with col2:
            if st.button("‚ùå X√≥a", key="delete_data"):
                delete_faq(selected_question)
                st.success("‚úÖ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c x√≥a!")

    with tab_statistics:
        show_statistics()

    with tab_load_logs:
        st.header("üìã Qu·∫£n l√Ω C√¢u H·ªèi Ch∆∞a Tr·∫£ L·ªùi")
        logs = load_unanswered_questions()
        if logs:
            questions = [log[0] for log in logs]  # Thay ƒë·ªïi ch·ªâ s·ªë
            selected_question = st.selectbox(
                "‚ùì C√¢u h·ªèi ch∆∞a tr·∫£ l·ªùi:", questions, key="unanswered_questions_selectbox")

            st.markdown("### ‚úèÔ∏è Nh·∫≠p c√¢u tr·∫£ l·ªùi:")
            answer = st.text_area(
                "C√¢u tr·∫£ l·ªùi:", key="unanswered_questions_textarea")

            col1, col2 = st.columns([1, 3])
            with col1:
                if st.button("üíæ L∆∞u", key="save_log_answer"):
                    if selected_question and answer:
                        if add_faq(selected_question, answer):
                            st.success("‚úÖ C√¢u tr·∫£ l·ªùi ƒë√£ ƒë∆∞·ª£c l∆∞u!")
                        else:
                            st.warning("‚ö†Ô∏è C√¢u h·ªèi ƒë√£ t·ªìn t·∫°i!")
                    else:
                        st.error("‚õî Vui l√≤ng nh·∫≠p ƒë·∫ßy ƒë·ªß th√¥ng tin!")
            with col2:
                st.empty()  # Gi·ªØ kho·∫£ng tr·ªëng ƒë·ªÉ cƒÉn ch·ªânh n√∫t l∆∞u
        else:
            st.info("üì≠ Kh√¥ng c√≥ c√¢u h·ªèi ch∆∞a ƒë∆∞·ª£c tr·∫£ l·ªùi.")

    with tab_generate_question:
        st.subheader("ü§ñ T·ª± ƒë·ªông sinh c√¢u h·ªèi t·ª´ t√†i li·ªáu PDF")

    # Hi·ªÉn th·ªã danh s√°ch PDF
    docs_path = Path("D:\\chatbot\\docs")
    docs = [file.name for file in docs_path.iterdir()
            if file.suffix.lower() == ".pdf"]

    if not docs:
        st.warning("Kh√¥ng t√¨m th·∫•y file PDF n√†o trong th∆∞ m·ª•c docs")
        return

    selected_doc = st.selectbox("üìÑ Ch·ªçn t√†i li·ªáu:", docs)

    col1, col2 = st.columns([1, 3])
    with col1:
        if st.button("üéØ B·∫Øt ƒë·∫ßu sinh c√¢u h·ªèi", key="generate_qa"):
            pdf_path = docs_path / selected_doc
            qa_pairs = process_pdf_and_generate_qa(pdf_path)

            if qa_pairs:
                st.session_state.qa_pairs = qa_pairs
                st.success(
                    f"ƒê√£ sinh ƒë∆∞·ª£c {len(qa_pairs)} c·∫∑p c√¢u h·ªèi - tr·∫£ l·ªùi")
            else:
                st.error("Kh√¥ng th·ªÉ sinh c√¢u h·ªèi t·ª´ t√†i li·ªáu n√†y")

    # Hi·ªÉn th·ªã k·∫øt qu·∫£ n·∫øu c√≥
    if hasattr(st.session_state, 'qa_pairs'):
        st.subheader("üìù K·∫øt qu·∫£ sinh c√¢u h·ªèi - tr·∫£ l·ªùi")
        for i, (question, answer) in enumerate(st.session_state.qa_pairs):
            with st.expander(f"C√¢u h·ªèi {i+1}: {question}"):
                st.write("**C√¢u tr·∫£ l·ªùi:**", answer)
                if st.button(f"üíæ L∆∞u Q&A #{i+1}", key=f"save_qa_{i}"):
                    if add_faq(question, answer):
                        st.success("‚úÖ ƒê√£ l∆∞u th√†nh c√¥ng!")
                    else:
                        st.warning("‚ö†Ô∏è C√¢u h·ªèi n√†y ƒë√£ t·ªìn t·∫°i!")
