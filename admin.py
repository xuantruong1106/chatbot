from sentence_transformers import SentenceTransformer
import streamlit as st
import pandas as pd
import torch
from connectsql import (
    connect_to_postgresql, is_question_duplicate, load_faq, add_faq,
    load_unanswered_logs, load_unanswered_questions, show_statistics, update_faq, delete_faq
)
from pathlib import Path
from transformers import pipeline
from sentence_transformers import util
from PyPDF2 import PdfReader
from transformers import pipeline, GPT2LMHeadModel, GPT2Tokenizer
from transformers import T5ForConditionalGeneration, AutoTokenizer
import logging
from typing import List, Tuple, Optional
from tqdm import tqdm
import numpy as np
import re

# Thiáº¿t láº­p logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

docs_path = Path("D:\\chatbot\\docs")


def is_question_duplicate(question):
    try:
        conn = connect_to_postgresql()
        cursor = conn.cursor()

        cursor.execute(
            "SELECT COUNT(*) FROM faq WHERE question = %s", (question,))
        count = cursor.fetchone()[0]

        cursor.close()
        conn.close()

        return count > 0
    except Exception as e:
        print(f"Lá»—i khi kiá»ƒm tra cÃ¢u há»i: {e}")
        return False


class QAGenerator:
    def __init__(self):
        self.device = torch.device(
            'cuda' if torch.cuda.is_available() else 'cpu')
        self.model = T5ForConditionalGeneration.from_pretrained(
            "VietAI/vit5-base").to(self.device)
        self.tokenizer = AutoTokenizer.from_pretrained("VietAI/vit5-base")
        self.similarity_model = SentenceTransformer(
            'VoVanPhuc/sup-SimCSE-VietNamese-phobert-base')

    def preprocess_text(self, text: str) -> str:
        # Chuáº©n hÃ³a text
        text = re.sub(r'\s+', ' ', text)
        text = text.strip()
        return text

    def postprocess_text(self, text: str) -> str:
        # Xá»­ lÃ½ output
        text = re.sub(
            r'[^\x00-\x7F\u0100-\u017F\u0180-\u024F\u1EA0-\u1EF9\u0300-\u036f]+', '', text)
        text = re.sub(r'\s+', ' ', text)
        return text.strip()

    def generate_question(self, context: str) -> list[str]:
        context = self.preprocess_text(context)
        input_text = f"hÃ£y Ä‘áº·t cÃ¢u há»i dá»±a trÃªn Ä‘oáº¡n vÄƒn sau: {context}"

        inputs = self.tokenizer(input_text,
                                return_tensors="pt",
                                max_length=512,
                                truncation=True).to(self.device)

        outputs = self.model.generate(
            inputs.input_ids,
            max_length=128,
            min_length=10,
            num_return_sequences=3,
            num_beams=5,
            temperature=0.7,
            top_k=50,
            top_p=0.95,
            no_repeat_ngram_size=2,
            do_sample=True
        )

        questions = []
        for output in outputs:
            question = self.tokenizer.decode(output, skip_special_tokens=True)
            question = self.postprocess_text(question)
            if len(question) > 10:
                questions.append(question)

        return questions

    def generate_answer(self, question: str, context: str) -> str:
        question = self.preprocess_text(question)
        context = self.preprocess_text(context)

        input_text = f"tráº£ lá»i cÃ¢u há»i sau dá»±a trÃªn Ä‘oáº¡n vÄƒn: cÃ¢u há»i: {question} Ä‘oáº¡n vÄƒn: {context}"

        inputs = self.tokenizer(input_text,
                                return_tensors="pt",
                                max_length=512,
                                truncation=True).to(self.device)

        outputs = self.model.generate(
            inputs.input_ids,
            max_length=256,
            min_length=20,
            num_beams=5,
            temperature=0.7,
            top_k=50,
            top_p=0.95,
            no_repeat_ngram_size=2
        )

        answer = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
        return self.postprocess_text(answer)

    def evaluate_qa_quality(self, question: str, answer: str, context: str) -> bool:
        # Kiá»ƒm tra Ä‘á»™ dÃ i tá»‘i thiá»ƒu
        if len(question) < 10 or len(answer) < 20:
            return False

        # Kiá»ƒm tra cháº¥t lÆ°á»£ng vÄƒn báº£n
        if not re.match(r'^[\w\s\.,\?\!]+$', question) or not re.match(r'^[\w\s\.,\?\!]+$', answer):
            return False

        # ÄÃ¡nh giÃ¡ Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng
        try:
            embeddings = self.similarity_model.encode(
                [question, answer, context])
            q_c_similarity = np.dot(embeddings[0], embeddings[2])
            a_c_similarity = np.dot(embeddings[1], embeddings[2])
            return q_c_similarity > 0.5 and a_c_similarity > 0.6
        except:
            return False


class PDFProcessor:
    @staticmethod
    def get_pdf_text(pdf_path: Path) -> str:
        try:
            reader = PdfReader(pdf_path)
            text = ""
            for page in reader.pages:
                text += page.extract_text()
            return text
        except Exception as e:
            logger.error(f"Lá»—i Ä‘á»c PDF: {e}")
            return ""

    @staticmethod
    def improve_chunk_quality(text: str, chunk_size: int = 512, overlap: int = 50) -> List[str]:
        try:
            sentences = text.split('.')
            chunks = []
            current_chunk = []
            current_length = 0

            for sentence in sentences:
                sentence = sentence.strip() + '.'
                sentence_length = len(sentence.split())

                if current_length + sentence_length > chunk_size:
                    if current_chunk:
                        chunks.append(' '.join(current_chunk))
                    current_chunk = [sentence]
                    current_length = sentence_length
                else:
                    current_chunk.append(sentence)
                    current_length += sentence_length

            if current_chunk:
                chunks.append(' '.join(current_chunk))

            return chunks
        except Exception as e:
            logger.error(f"Lá»—i xá»­ lÃ½ chunks: {e}")
            return []


def process_pdf_and_generate_qa(pdf_path: Path) -> List[Tuple[str, str]]:
    try:
        processor = PDFProcessor()
        generator = QAGenerator()

        # Äá»c vÃ  xá»­ lÃ½ PDF
        pdf_text = processor.get_pdf_text(pdf_path)
        if not pdf_text:
            st.error("KhÃ´ng thá»ƒ Ä‘á»c ná»™i dung PDF")
            return []

        # Chia thÃ nh chunks vÃ  sinh Q&A
        chunks = processor.improve_chunk_quality(pdf_text)
        qa_pairs = []

        with st.spinner("Äang sinh cÃ¢u há»i vÃ  cÃ¢u tráº£ lá»i..."):
            progress_bar = st.progress(0)
            for i, chunk in enumerate(chunks):
                if len(chunk.strip()) < 50:
                    continue

                questions = generator.generate_question(chunk)
                for question in questions:
                    answer = generator.generate_answer(question, chunk)
                    if answer and generator.evaluate_qa_quality(question, answer, chunk):
                        qa_pairs.append((question, answer))

                progress_bar.progress((i + 1) / len(chunks))

        return qa_pairs

    except Exception as e:
        logger.error(f"Lá»—i trong quÃ¡ trÃ¬nh xá»­ lÃ½: {e}")
        st.error(f"CÃ³ lá»—i xáº£y ra: {str(e)}")
        return []


def admin_interface():
    if not st.session_state.get('authenticated', False):
        st.warning("Báº¡n chÆ°a Ä‘Äƒng nháº­p. Vui lÃ²ng Ä‘Äƒng nháº­p trÆ°á»›c.")
        st.stop()

    # Sidebar
    with st.sidebar:
        st.header("ğŸ” ThÃ´ng tin tÃ i khoáº£n")
        st.write(f"**ğŸ‘¤ TÃªn ngÆ°á»i dÃ¹ng:** {st.session_state['username']}")
        st.write(
            f"**ğŸ”“ Vai trÃ²:** {'Admin' if st.session_state['username'] == 'admin' else 'NgÆ°á»i dÃ¹ng'}")
        st.divider()
        if st.button("ğŸšªÄÄƒng xuáº¥t"):
            st.session_state['authenticated'] = False
            st.rerun()

    st.title("âœ¨ Quáº£n lÃ½ Dá»¯ liá»‡u Chatbot")

    # Tabs chÃ­nh
    tab_add, tab_edit, tab_load_logs, tab_statistics, tab_generate_question = st.tabs(
        ["â• ThÃªm Dá»¯ liá»‡u", "âœï¸ Chá»‰nh sá»­a Dá»¯ liá»‡u",
            "ğŸ“‹ Quáº£n lÃ½ Log", "Thá»‘ng kÃª", "ğŸª„ Dá»± Ä‘oÃ¡n dá»¯ liá»‡u"]
    )

    with tab_add:
        st.header("â• ThÃªm Dá»¯ liá»‡u")
        st.markdown("### Nháº­p thÃ´ng tin cÃ¢u há»i vÃ  cÃ¢u tráº£ lá»i:")
        col1, col2 = st.columns(2)
        with col1:
            question = st.text_input("CÃ¢u há»i:")
        with col2:
            answer = st.text_area("CÃ¢u tráº£ lá»i:")

        st.markdown("---")
        if st.button("ThÃªm vÃ o FAQ", key="add_data"):
            if question and answer:
                if add_faq(question, answer):
                    st.success("âœ… Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c thÃªm thÃ nh cÃ´ng!")
                else:
                    st.warning("âš ï¸ CÃ¢u há»i nÃ y Ä‘Ã£ tá»“n táº¡i!")
            else:
                st.error("â›” Vui lÃ²ng nháº­p Ä‘áº§y Ä‘á»§ thÃ´ng tin!")

        with st.expander("ğŸ“„ Upload File PDF"):
            uploaded_pdf = st.file_uploader("Chá»n file PDF:", type="pdf")
            if uploaded_pdf:
                pdf_path = docs_path / uploaded_pdf.name
                with open(pdf_path, "wb") as f:
                    f.write(uploaded_pdf.getbuffer())
                st.success(f"ğŸ“‚ File **{uploaded_pdf.name}** Ä‘Ã£ Ä‘Æ°á»£c lÆ°u!")

        st.markdown("---")
        st.subheader("ğŸ“„ Upload File Excel")

        uploaded_excel = st.file_uploader(
            "Chá»n file Excel Ä‘á»ƒ upload:", type=["xlsx", "xls"])

        if uploaded_excel:
            try:
                df = pd.read_excel(uploaded_excel)
                if st.button("ThÃªm dá»¯ liá»‡u tá»« Excel", key="add_from_excel"):
                    added_count = 0
                    skipped_count = 0
                    for _, row in df.iterrows():
                        question, answer = row['Question'], row['Answer']
                        if question and answer:
                            if is_question_duplicate(question):
                                skipped_count += 1  # Äáº¿m sá»‘ cÃ¢u há»i bá»‹ bá» qua
                            else:
                                if add_faq(question, answer):
                                    added_count += 1  # Äáº¿m sá»‘ cÃ¢u há»i Ä‘Æ°á»£c thÃªm
                    st.success(
                        f"âœ… ÄÃ£ thÃªm {added_count} cÃ¢u há»i tá»« file Excel!")
                    if skipped_count > 0:
                        st.warning(
                            f"âš ï¸ Bá» qua {skipped_count} cÃ¢u há»i do Ä‘Ã£ tá»“n táº¡i trong cÆ¡ sá»Ÿ dá»¯ liá»‡u.")
                else:
                    st.error("â›” File Excel pháº£i cÃ³ cá»™t 'Question' vÃ  'Answer'!")
            except Exception as e:
                st.error(f"â›” Lá»—i khi Ä‘á»c file Excel: {e}")

    with tab_edit:
        st.header("âœï¸ Chá»‰nh sá»­a Dá»¯ liá»‡u")  # ThÃªm biá»ƒu tÆ°á»£ng cho tiÃªu Ä‘á»
        questions, faq_data = load_faq()  # Giáº£ sá»­ faq_data chá»©a cáº£ cÃ¢u tráº£ lá»i

        # Há»™p chá»n cÃ¢u há»i vá»›i biá»ƒu tÆ°á»£ng
        selected_question = st.selectbox("ğŸ” Chá»n cÃ¢u há»i:", questions)

        # TÃ¬m cÃ¢u tráº£ lá»i tÆ°Æ¡ng á»©ng vá»›i cÃ¢u há»i Ä‘Ã£ chá»n
        current_answer = faq_data[selected_question]

        # Nháº­p cÃ¢u há»i má»›i vÃ  cÃ¢u tráº£ lá»i má»›i
        new_question = st.text_input(
            "âœï¸ Cáº­p nháº­t cÃ¢u há»i:", value=selected_question)
        # Hiá»ƒn thá»‹ cÃ¢u tráº£ lá»i cÅ©
        new_answer = st.text_area(
            "ğŸ“ Cáº­p nháº­t cÃ¢u tráº£ lá»i:", value=current_answer)

        col1, col2 = st.columns(2)

        # Cá»™t Cáº­p nháº­t vá»›i biá»ƒu tÆ°á»£ng
        with col1:
            if st.button("âœ”ï¸ Cáº­p nháº­t", key="update_data"):
                update_faq(selected_question, new_question, new_answer)
                st.success("âœ… Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c cáº­p nháº­t!")

        # Cá»™t XÃ³a vá»›i biá»ƒu tÆ°á»£ng
        with col2:
            if st.button("âŒ XÃ³a", key="delete_data"):
                delete_faq(selected_question)
                st.success("âœ… Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c xÃ³a!")

    with tab_statistics:
        show_statistics()

    with tab_load_logs:
        st.header("ğŸ“‹ Quáº£n lÃ½ CÃ¢u Há»i ChÆ°a Tráº£ Lá»i")
        logs = load_unanswered_questions()
        if logs:
            questions = [log[0] for log in logs]  # Thay Ä‘á»•i chá»‰ sá»‘
            selected_question = st.selectbox(
                "â“ CÃ¢u há»i chÆ°a tráº£ lá»i:", questions, key="unanswered_questions_selectbox")

            st.markdown("### âœï¸ Nháº­p cÃ¢u tráº£ lá»i:")
            answer = st.text_area(
                "CÃ¢u tráº£ lá»i:", key="unanswered_questions_textarea")

            col1, col2 = st.columns([1, 3])
            with col1:
                if st.button("ğŸ’¾ LÆ°u", key="save_log_answer"):
                    if selected_question and answer:
                        if add_faq(selected_question, answer):
                            st.success("âœ… CÃ¢u tráº£ lá»i Ä‘Ã£ Ä‘Æ°á»£c lÆ°u!")
                        else:
                            st.warning("âš ï¸ CÃ¢u há»i Ä‘Ã£ tá»“n táº¡i!")
                    else:
                        st.error("â›” Vui lÃ²ng nháº­p Ä‘áº§y Ä‘á»§ thÃ´ng tin!")
            with col2:
                st.empty()  # Giá»¯ khoáº£ng trá»‘ng Ä‘á»ƒ cÄƒn chá»‰nh nÃºt lÆ°u
        else:
            st.info("ğŸ“­ KhÃ´ng cÃ³ cÃ¢u há»i chÆ°a Ä‘Æ°á»£c tráº£ lá»i.")

    with tab_generate_question:
        st.subheader("ğŸ¤– Tá»± Ä‘á»™ng sinh cÃ¢u há»i tá»« tÃ i liá»‡u PDF")

    # Hiá»ƒn thá»‹ danh sÃ¡ch PDF
    docs_path = Path("D:\\chatbot\\docs")
    docs = [file.name for file in docs_path.iterdir()
            if file.suffix.lower() == ".pdf"]

    if not docs:
        st.warning("KhÃ´ng tÃ¬m tháº¥y file PDF nÃ o trong thÆ° má»¥c docs")
        return

    selected_doc = st.selectbox("ğŸ“„ Chá»n tÃ i liá»‡u:", docs)

    col1, col2 = st.columns([1, 3])
    with col1:
        if st.button("ğŸ¯ Báº¯t Ä‘áº§u sinh cÃ¢u há»i", key="generate_qa"):
            pdf_path = docs_path / selected_doc
            qa_pairs = process_pdf_and_generate_qa(pdf_path)

            if qa_pairs:
                st.session_state.qa_pairs = qa_pairs
                st.success(
                    f"ÄÃ£ sinh Ä‘Æ°á»£c {len(qa_pairs)} cáº·p cÃ¢u há»i - tráº£ lá»i")
            else:
                st.error("KhÃ´ng thá»ƒ sinh cÃ¢u há»i tá»« tÃ i liá»‡u nÃ y")

    # Hiá»ƒn thá»‹ káº¿t quáº£ náº¿u cÃ³
    if hasattr(st.session_state, 'qa_pairs'):
        st.subheader("ğŸ“ Káº¿t quáº£ sinh cÃ¢u há»i - tráº£ lá»i")
        for i, (question, answer) in enumerate(st.session_state.qa_pairs):
            with st.expander(f"CÃ¢u há»i {i+1}: {question}"):
                st.write("**CÃ¢u tráº£ lá»i:**", answer)
                if st.button(f"ğŸ’¾ LÆ°u Q&A #{i+1}", key=f"save_qa_{i}"):
                    if add_faq(question, answer):
                        st.success("âœ… ÄÃ£ lÆ°u thÃ nh cÃ´ng!")
                    else:
                        st.warning("âš ï¸ CÃ¢u há»i nÃ y Ä‘Ã£ tá»“n táº¡i!")
