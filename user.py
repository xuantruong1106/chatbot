import os
import time
from dotenv import load_dotenv
import streamlit as st
from PyPDF2 import PdfReader
from suggestion_file import select_suggestion
from rapidfuzz import process
from st_alys import compare_strings_highest_score
<<<<<<< HEAD
from connectsql import log_unanswered_question, mactching_with_load_from_postgresql, get_answer, get_answer_id_faq_from_key_word, save_pdf_answer_to_db
from langdetect import detect, DetectorFactory
from deep_translator import GoogleTranslator
import fitz  # PyMuPDF for reading PDF
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
=======
from connectsql import add_faq, mactching_with_load_from_postgresql, get_answer, get_answer_id_faq_from_key_word, load_from_postgresql, log_chat
from langdetect import detect, DetectorFactory
from deep_translator import GoogleTranslator
from langchain.text_splitter import CharacterTextSplitter
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import FAISS
from langchain.llms import HuggingFaceHub
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationalRetrievalChain
import pdfplumber
from pathlib import Path
>>>>>>> 0b7e18c05222ced16bd1d6a6d752b58353215d40

# C·∫•u h√¨nh ban ƒë·∫ßu
chat_container = st.empty()
DetectorFactory.seed = 0
pdf_path = Path("./docs")


def get_pdf_text(pdf_path):
    """ƒê·ªçc n·ªôi dung t·ª´ file PDF."""
    try:
        text = ""
        # L·∫•y danh s√°ch t·∫•t c·∫£ c√°c file PDF trong th∆∞ m·ª•c
        pdf_files = Path(pdf_path).glob("*.pdf")
        for pdf_file in pdf_files:
            with pdfplumber.open(pdf_file) as pdf_reader:
                for page in pdf_reader.pages:
                    text += page.extract_text() or ""
        return text
    except Exception as e:
        return f"L·ªói khi ƒë·ªçc PDF: {e}"


def get_text_chunks(text):
    """Chia n·ªôi dung vƒÉn b·∫£n th√†nh c√°c ƒëo·∫°n nh·ªè."""
    text_splitter = CharacterTextSplitter(
        separator="\n",
        chunk_size=1000,
        chunk_overlap=200,
        length_function=len
    )
    return text_splitter.split_text(text)

def get_vectorstore(text_chunks):
    embeddings = HuggingFaceEmbeddings(
        model_name="sentence-transformers/all-MiniLM-L6-v2")
    return FAISS.from_texts(texts=text_chunks, embedding=embeddings)


def get_conversation_chain(vectorstore):
    llm = HuggingFaceHub(
        repo_id="google/flan-t5-base",
        model_kwargs={"temperature": 0.5, "max_length": 1024}
    )
    memory = ConversationBufferMemory(
        memory_key='chat_history', return_messages=True)
    return ConversationalRetrievalChain.from_llm(llm=llm, retriever=vectorstore.as_retriever(), memory=memory)


# ƒê·ªçc n·ªôi dung t·ª´ m·ªôt file PDF
def read_pdf(file_path):
    text = ""
    with fitz.open(file_path) as doc:
        for page in doc:
            text += page.get_text()
    return text.split('. ')  # Chia th√†nh c√°c c√¢u

# ƒê·ªçc n·ªôi dung t·ª´ t·∫•t c·∫£ c√°c file PDF trong th∆∞ m·ª•c
def read_all_pdfs(directory_path):
    all_sentences = []
    for file_name in os.listdir(directory_path):
        if file_name.endswith('.pdf'):
            file_path = os.path.join(directory_path, file_name)
            sentences = read_pdf(file_path)
            all_sentences.extend(sentences)
    return all_sentences

# T√¨m c√¢u t∆∞∆°ng ƒë·ªìng nh·∫•t trong n·ªôi dung PDF
def find_best_match(question, pdf_content):
    if not pdf_content:
        return None 
    vectorizer = TfidfVectorizer().fit_transform([question] + pdf_content)
    vectors = vectorizer.toarray()
    cosine_similarities = cosine_similarity(vectors[0:1], vectors[1:]).flatten()
    best_match_index = cosine_similarities.argmax()
    best_score = cosine_similarities[best_match_index]
    return pdf_content[best_match_index] if best_score >= 0.2 else None  # Ng∆∞·ª°ng t∆∞∆°ng ƒë·ªìng l√† 30%

def detect_language(text):
    """Ph√°t hi·ªán ng√¥n ng·ªØ c·ªßa vƒÉn b·∫£n."""
    try:
        return detect(text)
    except Exception as e:
        return f"L·ªói nh·∫≠n bi·∫øt ng√¥n ng·ªØ: {e}"

<<<<<<< HEAD
def translate_text(text, target_lang, detected_lang):
    try:
        translation = GoogleTranslator(
            source=detected_lang, target=target_lang).translate(text)
        return translation
    except Exception as e:
        return None, f"L·ªói d·ªãch thu·∫≠t: {e}"

def handle_user_input(user_input, pdf_content=None):
    # T√¨m c√¢u tr·∫£ l·ªùi t·ª´ c∆° s·ªü d·ªØ li·ªáu
=======

def translate_text(text, target_lang, detected_lang):
    """D·ªãch vƒÉn b·∫£n sang ng√¥n ng·ªØ ƒë√≠ch."""
    try:
        return GoogleTranslator(source=detected_lang, target=target_lang).translate(text)
    except Exception as e:
        return None


def handle_user_input(user_input):
    """X·ª≠ l√Ω ƒë·∫ßu v√†o t·ª´ ng∆∞·ªùi d√πng ƒë·ªÉ t√¨m c√¢u tr·∫£ l·ªùi trong c∆° s·ªü d·ªØ li·ªáu."""
>>>>>>> 0b7e18c05222ced16bd1d6a6d752b58353215d40
    matching = mactching_with_load_from_postgresql(user_input)
    if matching:
        return get_answer(user_input)
    elif matching == False:
        return get_answer_id_faq_from_key_word(user_input)
    else:
<<<<<<< HEAD
        answer = 'error'
        is_answer = False

    # N·∫øu kh√¥ng t√¨m th·∫•y c√¢u tr·∫£ l·ªùi, ki·ªÉm tra n·ªôi dung PDF
    if not is_answer and pdf_content:
        pdf_match = find_best_match(user_input, pdf_content)
        if pdf_match:
            answer = pdf_match
            is_answer = True
            save_pdf_answer_to_db(user_input, answer)  # L∆∞u c√¢u h·ªèi v√† c√¢u tr·∫£ l·ªùi v√†o c∆° s·ªü d·ªØ li·ªáu

    # N·∫øu kh√¥ng t√¨m th·∫•y c√¢u tr·∫£ l·ªùi trong c∆° s·ªü d·ªØ li·ªáu v√† PDF
    if not is_answer:
        answer = "R·∫•t c·∫£m ∆°n c√¢u h·ªèi, nh√† tr∆∞·ªùng s·∫Ω gi·∫£i ƒë√°p c√¢u h·ªèi c·ªßa b·∫°n sau."
        log_unanswered_question(user_input)  # L∆∞u v√†o b·∫£ng m·ªõi

    return answer or "Xin l·ªói, hi·ªán t·∫°i kh√¥ng t√¨m th·∫•y c√¢u tr·∫£ l·ªùi ph√π h·ª£p.", is_answer

def user_interface():
    
    if not st.session_state.get('authenticated', False):
        st.warning("B·∫°n ch∆∞a ƒëƒÉng nh·∫≠p. Vui l√≤ng ƒëƒÉng nh·∫≠p tr∆∞·ªõc.")
        st.stop()

    # Sidebar
    with st.sidebar:
        st.header("üîê Th√¥ng tin t√†i kho·∫£n")
        st.write(f"**üë§ T√™n ng∆∞·ªùi d√πng:** {st.session_state['username']}")
        st.write(f"**üîì Vai tr√≤:** {'Admin' if st.session_state['username'] == 'admin' else 'Ng∆∞·ªùi d√πng'}")
        st.divider()
        if st.button("üö™ƒêƒÉng xu·∫•t"):
            st.session_state['authenticated'] = False
            st.rerun()
            
            
    st.title("ü§ñ Chatbot Gi·∫£i ƒê√°p Th·∫Øc M·∫Øc")
=======
        return 'Kh√¥ng t√¨m th·∫•y c√¢u tr·∫£ l·ªùi.', False


def handle_input_with_pdf(user_question):
    """T√¨m c√¢u tr·∫£ l·ªùi t·ª´ PDF n·∫øu kh√¥ng c√≥ trong c∆° s·ªü d·ªØ li·ªáu."""
    response = st.session_state.conversation({'question': user_question})
    if 'chat_history' in response:
        chat_history = response['chat_history']
        return chat_history[-1].content, True
    return None, False


def user_interface():
    """Giao di·ªán ch√≠nh c·ªßa ·ª©ng d·ª•ng."""
    load_dotenv()
    st.title("Chatbot Gi·∫£i ƒê√°p Th·∫Øc M·∫Øc")
>>>>>>> 0b7e18c05222ced16bd1d6a6d752b58353215d40

    if "messages" not in st.session_state:
        st.session_state.messages = []

    if "username" not in st.session_state:
        st.session_state.username = "Ng∆∞·ªùi d√πng"

    raw_text = get_pdf_text(pdf_path)

    print("D·ªãch n·ªôi dung PDF sang ti·∫øng Anh...")
    translated_text = translate_text(
        raw_text, detected_lang="vi", target_lang="en")
    
  
    text_chunks = get_text_chunks(translated_text)
    
    vectorstore = get_vectorstore(text_chunks)

    st.session_state.conversation = get_conversation_chain(vectorstore)

    with st.container():
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

    with st.form(key="chat_form", clear_on_submit=True):
        user_input = st.text_input(
            "Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n:", placeholder="V√≠ d·ª•: H·ªçc ph√≠ c·ªßa tr∆∞·ªùng l√† bao nhi√™u?")
        submit_button = st.form_submit_button("üíæ G·ª≠i")

<<<<<<< HEAD
        # ƒê∆∞·ªùng d·∫´n ƒë·∫øn th∆∞ m·ª•c ch·ª©a file PDF
        pdf_directory = "docs"
        pdf_content = read_all_pdfs(pdf_directory)

        if submit_button and user_input.strip():
            st.session_state.messages.append({"role": "user", "content": user_input})

            # X·ª≠ l√Ω ng√¥n ng·ªØ
            lang = detect_language(user_input)
            if lang != 'vi':
                user_input = translate_text(text=user_input, target_lang='vi', detected_lang=lang)

            answer, is_answered = handle_user_input(user_input, pdf_content=pdf_content)
            st.session_state.messages.append({"role": "assistant", "content": f"```\n{answer}\n```"})

            st.rerun()
=======
        if submit_button and user_input.strip():
            st.session_state.messages.append(
                {"role": "user", "content": user_input})

            lang = detect_language(user_input)
            if lang != 'vi':
                user_input = translate_text(
                    user_input, target_lang='vi', detected_lang=lang)

            print("ƒê·∫ßu v√†o:", user_input)

            answer, is_answered = None, False

            question_suggestions = select_suggestion(user_input)
            print("C√°c c√¢u h·ªèi g·∫ßn nh·∫•t: ", question_suggestions)

            # question_suggestions = select_suggestion(user_input)

            # if question_suggestions:
            #     answer, is_answered = handle_user_input(user_input)
            #     have_answer = 1
            #     log_chat(st.session_state['username'],
            #              user_input, answer, is_answered)
            # else:
            for question in load_from_postgresql():
                print("Question: ", question)
                if compare_strings_highest_score(user_input, question):
                    print("C√¢u h·ªèi ƒë√∫ng: ", question)
                    answer, is_answered = handle_user_input(question)
                    log_chat(
                        st.session_state['username'], user_input, answer, is_answered)
                    break

            # answer, is_answered = handle_user_input(user_input)

            if is_answered == False:
                print("Kh√¥ng t√¨m th·∫•y c√¢u tr·∫£ l·ªùi trong c∆° s·ªü d·ªØ li·ªáu.")
                question = translate_text(
                    user_input, detected_lang="vi", target_lang="en")
                answer, is_answered = handle_input_with_pdf(question)
                print("D·ªãch c√¢u tr·∫£ l·ªùi sang ti·∫øng Vi·ªát...")
                answer = translate_text(
                    answer, detected_lang="en", target_lang="vi")
                add_faq(user_input, answer)
                print("ƒê√£ th√™m v√†o csdl")
                log_chat(st.session_state['username'],
                         user_input, answer, is_answered)
                print("C√¢u tr·∫£ l·ªùi:", answer)

            if not answer:
                answer = 'R·∫•t c·∫£m ∆°n c√¢u h·ªèi, nh√† tr∆∞·ªùng s·∫Ω gi·∫£i ƒë√°p sau.'

            answer_lang = detect_language(answer)
            if answer_lang == 'vi' and lang != 'vi':
                answer = translate_text(
                    answer, target_lang=lang, detected_lang='vi')
            print("C√¢u tr·∫£ l·ªùi:", answer)

            st.session_state.messages.append(
                {"role": "assistant", "content": f"```\n{answer}\n```"})

            log_chat(st.session_state['username'],
                     user_input, answer, is_answered)

            st.rerun()


if __name__ == "__main__":
    user_interface()
>>>>>>> 0b7e18c05222ced16bd1d6a6d752b58353215d40
